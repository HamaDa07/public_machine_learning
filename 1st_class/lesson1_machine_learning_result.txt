5000>4000>1000

epochs=7500 is best
batchs=1    is best



標準
epochs=3000
batchs=1
隠れ層　:　1層
入力層のニューロン数:2
活性化関数はシグモイド
(sigmoid)

#エポック(実行)
の回数と誤差

1万回					
[0.24538562]
 [0.8576066 ]
 [0.7578947 ]
 [0.20130202]]

1千回
[0.10022411]
 [0.7627665 ]
 [0.8139291 ]
 [0.37962955

7500回
[0.00286767]
 [0.9978226 ]
 [0.9944011 ]
 [0.00344655]]

5000回
[0.00426605]
 [0.99700296]
 [0.9952395 ]
 [0.00343111]


#バッチの回数
#バッチの回数が少ないと精度は上がるが、実行時間が長くなる

--エポック3000
 2回
[[0.03399217]
 [0.966494  ]
 [0.9698515 ]
 [0.04155737]]

 3回
[[0.11725217]
 [0.90233976]
 [0.8924875 ]
 [0.11607242]]

 4回
[[0.29325426]
 [0.4954114 ]
 [0.8325086 ]
 [0.4133838 ]]

#隠れ層のニューロン数
#隠れ層のニューロン数を増やすと精度が上がる

units=3 (2個)
[[0.01345363]
 [0.98925185]
 [0.98915815]
 [0.01181322]]

units=4 (3個)
[[0.00581947]
 [0.9898672 ]
 [0.9924294 ]
 [0.01634178]]

#隠れ層を増やす
2回がベスト
3回は、過学習

#最終的な入力のニューロン数を増やしても結果は大して変わらない(増やした方がいい)

1回(標準)
[[0.01345363]
 [0.98925185]
 [0.98915815]
 [0.01181322]]

2回
[[0.00298449]
 [0.99692154]
 [0.9969487 ]
 [0.00249541]]

3回
[[0.4997777 ]
 [0.5005045 ]
 [0.5001517 ]
 [0.50067943]]

